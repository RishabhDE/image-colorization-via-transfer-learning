{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b42298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, BatchNormalization, LeakyReLU, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from Data_processing_functions import *\n",
    "from Pix2Pix_model import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233aad88",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c892b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load and preprocess image\n",
    "def load_and_preprocess_image(image_path, target_size, is_grayscale=False):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    channels = 1 if is_grayscale else 3\n",
    "    img = tf.image.decode_jpeg(img, channels=channels)\n",
    "    img = tf.image.resize(img, target_size)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Convert RGB image to LAB using OpenCV (requires numpy conversion)\n",
    "def convert_to_lab(image):\n",
    "    image_np = image.numpy() * 255.0  # Convert to 0-255 range for OpenCV\n",
    "    image_np = image_np.astype(np.uint8)\n",
    "    lab_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
    "    lab_image = lab_image.astype(np.float32) / 255.0  # Normalize to 0-1\n",
    "    return lab_image\n",
    "\n",
    "# Wrapper to use convert_to_lab in TensorFlow pipeline\n",
    "def preprocess_lab_image(image):\n",
    "    lab_image = tf.py_function(func=convert_to_lab, inp=[image], Tout=tf.float32)\n",
    "    lab_image.set_shape([None, None, 3])  # Set shape to avoid shape issues in TensorFlow\n",
    "    return lab_image\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess(gray_path, lab_path, target_size):\n",
    "    gray_img = load_and_preprocess_image(gray_path, target_size, is_grayscale=True)\n",
    "    rgb_img = load_and_preprocess_image(lab_path, target_size, is_grayscale=False)\n",
    "    lab_img = preprocess_lab_image(rgb_img)\n",
    "    return gray_img, lab_img\n",
    "\n",
    "# Create dataset\n",
    "def create_dataset(gray_image_paths, lab_image_paths, target_size=(256, 256), batch_size=32):\n",
    "    gray_image_paths = tf.constant(gray_image_paths, dtype=tf.string)\n",
    "    lab_image_paths = tf.constant(lab_image_paths, dtype=tf.string)\n",
    "    \n",
    "    # Check if paths are correctly loaded\n",
    "    if len(gray_image_paths) == 0 or len(lab_image_paths) == 0:\n",
    "        raise ValueError(\"No image paths provided.\")\n",
    "    \n",
    "    # Define the dataset from image paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((gray_image_paths, lab_image_paths))\n",
    "    \n",
    "    # Map the dataset to preprocess images\n",
    "    def map_fn(gray_path, lab_path):\n",
    "        gray_img, lab_img = tf.py_function(\n",
    "            func=lambda x, y: load_and_preprocess(x, y, target_size),\n",
    "            inp=[gray_path, lab_path],\n",
    "            Tout=[tf.float32, tf.float32]\n",
    "        )\n",
    "        gray_img.set_shape([target_size[0], target_size[1], 1])\n",
    "        lab_img.set_shape([target_size[0], target_size[1], 3])\n",
    "        \n",
    "\n",
    "        return gray_img, lab_img\n",
    "    \n",
    "    dataset = dataset.map(map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# # Extract edges from an image\n",
    "# def extract_edges(image):\n",
    "#     edges = cv2.Canny((image * 255).astype(np.uint8), 100, 200)\n",
    "#     return edges / 255.0\n",
    "\n",
    "# # Process a single grayscale image: extract edges and combine with the original image\n",
    "# def process_single_image(gray_image):\n",
    "#     edges = extract_edges(gray_image)\n",
    "#     edges = tf.convert_to_tensor(edges, dtype=tf.float32)[..., tf.newaxis]\n",
    "#     combined = tf.concat([tf.expand_dims(gray_image, axis=-1), edges], axis=-1)\n",
    "#     return combined\n",
    "\n",
    "# # Combine grayscale image with edges\n",
    "# def combine_gray_and_edges(gray_img, lab_img):\n",
    "#     combined_images = []\n",
    "#     for i in range(gray_img.shape[0]):\n",
    "#         single_gray = gray_img[i].numpy()  # Convert to NumPy array\n",
    "#         combined_images.append(process_single_image(single_gray))\n",
    "#     combined_batch = tf.stack(combined_images, axis=0)\n",
    "#     return combined_batch, lab_img\n",
    "\n",
    "# # Create dataset with edges\n",
    "# def create_dataset_with_edges(original_dataset):\n",
    "#     dataset_with_edges = original_dataset.map(\n",
    "#         lambda gray_img, lab_img: tf.py_function(\n",
    "#             func=lambda x, y: combine_gray_and_edges(x, y),\n",
    "#             inp=[gray_img, lab_img],\n",
    "#             Tout=[tf.float32, tf.float32]\n",
    "#         ),\n",
    "#         num_parallel_calls=tf.data.AUTOTUNE\n",
    "#     )\n",
    "#     return dataset_with_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdcb63",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd7ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    'initial_filters': 48,         # Starting number of filters in the first layer\n",
    "    'kernel_size': 5,              # Size of the convolutional kernel\n",
    "    'num_layers': 5,               # Number of convolutional layers\n",
    "    'dropout_rate': 0.5,           # Dropout rate for regularization\n",
    "    'batch_norm': True,            # Use of batch normalization\n",
    "    'lambda_l1': 100,              # L1 regularization parameter\n",
    "    'learning_rate': 1e-3,         # Learning rate for the optimizer\n",
    "    'beta_1': 0.5,                 # Beta1 hyperparameter for the Adam optimizer\n",
    "    'batch_size': 32,               # Batch size for training\n",
    "    'epochs': 50,                 # Number of epochs for training\n",
    "    'dropout': True,               # Whether to use dropout\n",
    "    'input_shape': (256, 256, 1)   # Input shape of the images (3 channels for RGB)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257d222",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ee2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, BatchNormalization, LeakyReLU, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    'initial_filters': 48,\n",
    "    'kernel_size': 5,\n",
    "    'num_layers': 5,\n",
    "    'dropout_rate': 0.5,\n",
    "    'batch_norm': True,\n",
    "    'lambda_l1': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'beta_1': 0.5,\n",
    "    'batch_size': 1,\n",
    "    'epochs': 50,\n",
    "    'dropout': True,\n",
    "    'input_shape': (256, 256, 1)\n",
    "}\n",
    "\n",
    "# Define the downsampling and upsampling blocks\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(hyperparams['dropout_rate']))\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result\n",
    "\n",
    "# Define the Generator model\n",
    "def Generator(hyperparams):\n",
    "    inputs = tf.keras.layers.Input(shape=hyperparams['input_shape'])\n",
    "\n",
    "    down_stack = [downsample(hyperparams['initial_filters'] * (2 ** i), hyperparams['kernel_size'], apply_batchnorm=hyperparams['batch_norm']) for i in range(hyperparams['num_layers'])]\n",
    "    up_stack = [upsample(hyperparams['initial_filters'] * (2 ** i), hyperparams['kernel_size'], apply_dropout=hyperparams['dropout']) for i in range(hyperparams['num_layers']-1, 0, -1)]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, hyperparams['kernel_size'], strides=2, padding='same', kernel_initializer=initializer, activation='tanh')\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.concatenate([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Define the Discriminator model\n",
    "def Discriminator(hyperparams):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    inp = tf.keras.layers.Input(shape=hyperparams['input_shape'], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[*hyperparams['input_shape'][:2], 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar])\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "# Loss functions\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    total_gen_loss = gan_loss + (hyperparams['lambda_l1'] * l1_loss)\n",
    "    return total_gen_loss, gan_loss, l1_loss\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss\n",
    "\n",
    "# PSNR metric\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    psnr_value = tf.image.psnr(y_true, y_pred, max_val=max_pixel)\n",
    "    return tf.reduce_mean(psnr_value)\n",
    "\n",
    "# Training step function\n",
    "def train_step(generator, discriminator, input_image, target, generator_optimizer, discriminator_optimizer):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_total_loss, disc_loss\n",
    "\n",
    "# Training function without validation\n",
    "def model_fit(train_ds, hyperparams, checkpoint_prefix):\n",
    "    gen_losses = []\n",
    "    disc_losses = []\n",
    "\n",
    "    generator = Generator(hyperparams)\n",
    "    discriminator = Discriminator(hyperparams)\n",
    "\n",
    "    # Define the optimizers\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "\n",
    "    # Define checkpoints\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                     discriminator_optimizer=discriminator_optimizer,\n",
    "                                     generator=generator,\n",
    "                                     discriminator=discriminator)\n",
    "\n",
    "    for epoch in range(hyperparams['epochs']):\n",
    "        start = time.time()\n",
    "        epoch_gen_loss = 0\n",
    "        epoch_disc_loss = 0\n",
    "\n",
    "        # Progress bar\n",
    "        progbar = tf.keras.utils.Progbar(len(train_ds), stateful_metrics=['loss'])\n",
    "\n",
    "        for step, (input_image, target) in enumerate(train_ds):\n",
    "            gen_total_loss, disc_loss = train_step(generator, discriminator, input_image, target, generator_optimizer, discriminator_optimizer)\n",
    "            epoch_gen_loss += gen_total_loss\n",
    "            epoch_disc_loss += disc_loss\n",
    "\n",
    "            # Update progress bar\n",
    "            progbar.update(step + 1, [('gen_loss', gen_total_loss), ('disc_loss', disc_loss)])\n",
    "\n",
    "        gen_losses.append(epoch_gen_loss / len(train_ds))\n",
    "        disc_losses.append(epoch_disc_loss / len(train_ds))\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Gen Loss: {gen_losses[-1]}, Disc Loss: {disc_losses[-1]}, Time: {time.time() - start}')\n",
    "\n",
    "        # Early stopping logic\n",
    "        if len(gen_losses) > 1 and gen_losses[-1] > gen_losses[-2]:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    return gen_losses, disc_losses\n",
    "\n",
    "# Visualize losses\n",
    "def visualize_losses(gen_losses, disc_losses):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Generator and Discriminator Losses\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(gen_losses, label='Generator Loss')\n",
    "    plt.plot(disc_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Generator and Discriminator Losses')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93011ed5",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177a09e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Shapes:\n",
      "Input Image Shape: (32, 256, 256, 1)\n",
      "Target Shape: (32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define Data Directory\n",
    "\n",
    "dir_path = 'data'\n",
    "\n",
    "\n",
    "color_dir = os.path.join(dir_path, 'train_color')\n",
    "black_dir = os.path.join(dir_path, 'train_black')\n",
    "\n",
    "\n",
    "# List all images\n",
    "color_images_paths = glob.glob(os.path.join(color_dir, '*.jpg'))\n",
    "black_images_paths = glob.glob(os.path.join(black_dir, '*.jpg'))\n",
    "\n",
    "# Ensure there are images in both directories\n",
    "if not color_images_paths or not black_images_paths:\n",
    "    raise ValueError(\"No images found in one or both directories.\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_dataset(black_images_paths, color_images_paths, target_size=(256, 256), batch_size=hyperparams['batch_size'])\n",
    "\n",
    "# Shuffle the dataset with a smaller buffer size and prefetch\n",
    "dataset = dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#Print dataset shapes for verification\n",
    "for gray_img, lab_img in dataset.take(1):\n",
    "    print(\"Train Dataset Shapes:\")\n",
    "    print(f\"Input Image Shape: {gray_img.shape}\")\n",
    "    print(f\"Target Shape: {lab_img.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373804d",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a784e241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,392</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">115,584</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">461,568</span> │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,844,736</span> │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,375,872</span> │ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,748,672</span> │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ sequential_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,060,736</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ sequential_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,765,568</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">691,584</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,803</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)             │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m48\u001b[0m)      │           \u001b[38;5;34m1,392\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │         \u001b[38;5;34m115,584\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │         \u001b[38;5;34m461,568\u001b[0m │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │       \u001b[38;5;34m1,844,736\u001b[0m │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │       \u001b[38;5;34m7,375,872\u001b[0m │ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_5 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │      \u001b[38;5;34m14,748,672\u001b[0m │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1152\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │ sequential_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ sequential_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_6 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │      \u001b[38;5;34m11,060,736\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m576\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ sequential_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ sequential_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │       \u001b[38;5;34m2,765,568\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_2 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m288\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ sequential_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_8 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m96\u001b[0m)      │         \u001b[38;5;34m691,584\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_3 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m144\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ sequential_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_transpose_4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │          \u001b[38;5;34m10,803\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)             │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,076,515</span> (149.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,076,515\u001b[0m (149.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,070,659</span> (149.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,070,659\u001b[0m (149.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,856</span> (22.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,856\u001b[0m (22.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discriminator Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ target_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │                           │                 │ target_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ sequential_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ sequential_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ zero_padding2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,152</span> │ zero_padding2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_11        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ zero_padding2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> │ zero_padding2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ target_image (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_4 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m4\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │                           │                 │ target_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_9 (\u001b[38;5;33mSequential\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m4,096\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_10 (\u001b[38;5;33mSequential\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m131,584\u001b[0m │ sequential_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ sequential_11 (\u001b[38;5;33mSequential\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m525,312\u001b[0m │ sequential_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ zero_padding2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ sequential_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m2,097,152\u001b[0m │ zero_padding2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_11        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │           \u001b[38;5;34m2,048\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ zero_padding2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │           \u001b[38;5;34m8,193\u001b[0m │ zero_padding2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,768,385</span> (10.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,768,385\u001b[0m (10.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,766,593</span> (10.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,766,593\u001b[0m (10.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize models\n",
    "generator = Generator(hyperparams)\n",
    "discriminator = Discriminator(hyperparams)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Generator Summary:\")\n",
    "generator.summary()\n",
    "\n",
    "print(\"\\nDiscriminator Summary:\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6dc550",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528de02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, BatchNormalization, LeakyReLU, ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Data_processing_functions import *\n",
    "from Pix2Pix_model import *\n",
    "\n",
    "# Hyperparameters\n",
    "hyperparams = {\n",
    "    'initial_filters': 48,\n",
    "    'kernel_size': 5,\n",
    "    'num_layers': 5,\n",
    "    'dropout_rate': 0.5,\n",
    "    'batch_norm': True,\n",
    "    'lambda_l1': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'beta_1': 0.5,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'dropout': True,\n",
    "    'input_shape': (256, 256, 1)\n",
    "}\n",
    "\n",
    "# Define Data Directory\n",
    "dir_path = 'data'\n",
    "color_dir = os.path.join(dir_path, 'train_color')\n",
    "black_dir = os.path.join(dir_path, 'train_black')\n",
    "\n",
    "# List all images\n",
    "color_images_paths = glob.glob(os.path.join(color_dir, '*.jpg'))\n",
    "black_images_paths = glob.glob(os.path.join(black_dir, '*.jpg'))\n",
    "\n",
    "# Ensure there are images in both directories\n",
    "if not color_images_paths or not black_images_paths:\n",
    "    raise ValueError(\"No images found in one or both directories.\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_dataset(black_images_paths, color_images_paths, target_size=(256, 256), batch_size=hyperparams['batch_size'])\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.shuffle(buffer_size=len(color_images_paths), reshuffle_each_iteration=True)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(hyperparams)\n",
    "discriminator = Discriminator(hyperparams)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Generator Summary:\")\n",
    "generator.summary()\n",
    "\n",
    "print(\"\\nDiscriminator Summary:\")\n",
    "discriminator.summary()\n",
    "\n",
    "# Define the optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "\n",
    "# Define the checkpoint directory\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "# Create a checkpoint object\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "# Restore the latest checkpoint if it exists\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint:\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "    print(f\"Restored from checkpoint: {latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"Starting fresh training\")\n",
    "\n",
    "# Train the model\n",
    "gen_losses, disc_losses = model_fit(dataset, hyperparams, checkpoint_prefix)\n",
    "\n",
    "\n",
    "\n",
    "# Define the directory path\n",
    "model_dir = './Trained_models'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the models\n",
    "generator.save('./Trained_models/pix2pix_model_generator.keras')\n",
    "discriminator.save('./Trained_models/pix2pix_model_discriminator.keras')\n",
    "\n",
    "# Visualize losses\n",
    "def visualize_losses(gen_losses, disc_losses):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Generator and Discriminator Losses\n",
    "    plt.plot(gen_losses, label='Generator Loss')\n",
    "    plt.plot(disc_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Generator and Discriminator Losses')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_losses(gen_losses, disc_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6625ef",
   "metadata": {},
   "source": [
    "## Validating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85890be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random  # Import random module\n",
    "\n",
    "from Data_processing_functions import load_and_preprocess_image, preprocess_lab_image, load_and_preprocess\n",
    "\n",
    "# Create dataset for test images\n",
    "def create_test_dataset(gray_image_paths, target_size=(256, 256), batch_size=32):\n",
    "    gray_image_paths = tf.constant(gray_image_paths, dtype=tf.string)\n",
    "    \n",
    "    # Define the dataset from image paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(gray_image_paths)\n",
    "    \n",
    "    # Map the dataset to preprocess images\n",
    "    dataset = dataset.map(lambda gray_path: load_and_preprocess_image(gray_path, target_size, is_grayscale=True), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Function to generate colorful images\n",
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input, training=False)  # Set training=False for inference\n",
    "    return prediction\n",
    "\n",
    "# Function to convert LAB to RGB\n",
    "def lab_to_rgb(lab_image):\n",
    "    lab_image_np = lab_image.numpy() * 255.0  # Convert to 0-255 range for OpenCV\n",
    "    lab_image_np = lab_image_np.astype(np.uint8)\n",
    "    rgb_image = cv2.cvtColor(lab_image_np, cv2.COLOR_LAB2RGB)\n",
    "    rgb_image = rgb_image / 255.0  # Normalize to [0, 1]\n",
    "    return rgb_image\n",
    "\n",
    "# Function to show images\n",
    "def show_images(gray_images, color_images, predicted_images, num_images):\n",
    "    plt.figure(figsize=(18, 12))  # Adjusted height for 3 rows\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Display grayscale images (first row)\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(tf.squeeze(gray_images[i]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Grayscale Image')\n",
    "\n",
    "        # Display original color images (second row)\n",
    "        plt.subplot(3, num_images, i + 1 + num_images)\n",
    "        plt.imshow(tf.squeeze(color_images[i]))\n",
    "        plt.axis('off')\n",
    "        plt.title('Original Color Image')\n",
    "\n",
    "        # Display predicted images (third row)\n",
    "        predicted_rgb = lab_to_rgb(predicted_images[i])  # Convert LAB to RGB\n",
    "        plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "        plt.imshow(predicted_rgb)\n",
    "        plt.axis('off')\n",
    "        plt.title('Predicted Color Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Define directories\n",
    "black_test_dir = 'data/test_black'  # Update with your actual path\n",
    "color_test_dir = 'data/test_color'   # Update with your actual path\n",
    "\n",
    "# Load image paths\n",
    "black_image_paths = glob.glob(os.path.join(black_test_dir, '*.jpg'))\n",
    "color_image_paths = glob.glob(os.path.join(color_test_dir, '*.jpg'))\n",
    "\n",
    "# Randomly select five image paths\n",
    "black_images_test_paths = random.sample(black_image_paths, 5)\n",
    "color_images_test_paths = random.sample(color_image_paths, 5)\n",
    "\n",
    "# Ensure these paths are not empty\n",
    "assert len(black_images_test_paths) > 0, \"No black and white test images found.\"\n",
    "assert len(color_images_test_paths) > 0, \"No color test images found.\"\n",
    "\n",
    "\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = create_test_dataset(black_images_test_paths, target_size=(256, 256), batch_size=32)\n",
    "\n",
    "# Load the trained generator model\n",
    "generator = tf.keras.models.load_model('./Trained_models/pix2pix_model_generator.keras')\n",
    "\n",
    "\n",
    "\n",
    "# Collect images for display\n",
    "predicted_images_list = []\n",
    "original_images_list = []\n",
    "gray_images_list = []\n",
    "\n",
    "for gray_img_batch in test_dataset:\n",
    "    generated_images = generate_images(generator, gray_img_batch)\n",
    "    \n",
    "    for i in range(generated_images.shape[0]):\n",
    "        predicted_images_list.append(generated_images[i])\n",
    "        \n",
    "        # Get the grayscale image tensor from the dataset (assuming batches are consistent)\n",
    "        gray_img = gray_img_batch[i]\n",
    "        gray_images_list.append(gray_img)\n",
    "        \n",
    "        # Match the color image paths to generated images\n",
    "        original_color_img_path = color_images_test_paths[i % len(color_images_test_paths)]\n",
    "        original_color_img = load_and_preprocess_image(original_color_img_path, target_size=(256, 256), is_grayscale=False)\n",
    "        original_images_list.append(original_color_img)\n",
    "\n",
    "# Ensure the number of images to show is consistent\n",
    "num_images = min(len(predicted_images_list), len(original_images_list), len(gray_images_list))\n",
    "show_images(gray_images=gray_images_list, color_images=original_images_list, predicted_images=predicted_images_list, num_images=num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b4d386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is A056-5119\n",
      "\n",
      " Directory of C:\\Users\\mohds\\OneDrive\\Desktop\\MS_AAI\\Course_501_Intro_AI_A2\\image-colorization-via-transfer-learning\n",
      "\n",
      "07-08-2024  01:32    <DIR>          .\n",
      "05-08-2024  20:55    <DIR>          ..\n",
      "05-08-2024  19:41                54 .gitignore\n",
      "07-08-2024  01:32    <DIR>          .ipynb_checkpoints\n",
      "07-08-2024  00:52    <DIR>          __pycache__\n",
      "05-08-2024  20:56    <DIR>          data\n",
      "03-08-2024  23:15         7,765,010 Data_Processing.ipynb\n",
      "07-08-2024  00:54             3,850 Data_processing_functions.py\n",
      "07-08-2024  01:28           208,558 Full_model_pipeline.ipynb\n",
      "03-08-2024  23:08             1,091 LICENSE\n",
      "05-08-2024  20:56    <DIR>          Models\n",
      "07-08-2024  00:55             7,943 Pix2Pix_model.py\n",
      "07-08-2024  00:49             3,315 Pix2Pix_train.py\n",
      "03-08-2024  23:08                 2 README.md\n",
      "05-08-2024  20:56    <DIR>          Trained_models\n",
      "06-08-2024  00:22    <DIR>          training_checkpoints\n",
      "06-08-2024  11:52             4,632 validation.py\n",
      "               9 File(s)      7,994,455 bytes\n",
      "               8 Dir(s)  128,269,942,784 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620b53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
