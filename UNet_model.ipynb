{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 06:21:07.904425: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 06:21:07.908376: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 06:21:07.920458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 06:21:07.936298: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 06:21:07.940442: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 06:21:07.951989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 06:21:09.034180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Directory paths\n",
    "train_color_dir = os.path.join('data', 'train_color')\n",
    "train_gray_dir = os.path.join('data', 'train_black')\n",
    "test_color_dir = os.path.join('data', 'test_color')\n",
    "test_gray_dir = os.path.join('data', 'test_black')\n",
    "\n",
    "# Function to load and process images\n",
    "def load_images(color_dir, gray_dir, target_size=(256, 256)):\n",
    "    color_images = []\n",
    "    gray_images = []\n",
    "\n",
    "    color_files = os.listdir(color_dir)\n",
    "    gray_files = os.listdir(gray_dir)\n",
    "\n",
    "    for color_file, gray_file in zip(color_files, gray_files):\n",
    "        # Load and resize images\n",
    "        color_image = imread(os.path.join(color_dir, color_file))\n",
    "        gray_image = imread(os.path.join(gray_dir, gray_file))\n",
    "\n",
    "        # Resize images\n",
    "        color_image = resize(color_image, target_size)\n",
    "        gray_image = resize(gray_image, target_size)\n",
    "\n",
    "        # Convert to LAB\n",
    "        color_image_lab = rgb2lab(color_image)\n",
    "\n",
    "        # Append processed images to lists\n",
    "        color_images.append(color_image_lab)\n",
    "        gray_images.append(gray_image)\n",
    "\n",
    "    color_images = np.array(color_images)\n",
    "    gray_images = np.array(gray_images).reshape(-1, target_size[0], target_size[1], 1)\n",
    "\n",
    "    return gray_images, color_images\n",
    "\n",
    "# Load train and test images\n",
    "X_train_gray, y_train_color = load_images(train_color_dir, train_gray_dir)\n",
    "X_test_gray, y_test_color = load_images(test_color_dir, test_gray_dir)\n",
    "\n",
    "# Extract the AB channels from the LAB images\n",
    "y_train_ab = y_train_color[:, :, :, 1:] / 128\n",
    "y_test_ab = y_test_color[:, :, :, 1:] / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 05:04:41.931059: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 05:04:43.560102: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 05:04:44.006109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 05:04:45.083923: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 05:04:45.349752: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 05:04:46.472813: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 05:04:50.361030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 1 classes.\n",
      "Found 5000 images belonging to 1 classes.\n",
      "Found 739 images belonging to 1 classes.\n",
      "Found 739 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# U-Net Model Architecture\n",
    "def unet_model(input_shape=(256, 256, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = concatenate([up5, conv3], axis=3)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = concatenate([up6, conv2], axis=3)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = concatenate([up7, conv1], axis=3)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    outputs = Conv2D(2, (1, 1), activation='tanh', padding='same')(conv7)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = unet_model()\n",
    "\n",
    "# Compile and Train\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[psnr])  # Ensure 'psnr' is defined\n",
    "\n",
    "# Train the model using new datasets\n",
    "model.fit(\n",
    "    X_train_gray, y_train_ab,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test_gray, y_test_ab),\n",
    "    callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Evaluate the Model\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test_gray, y_test_ab, batch_size=16)\n",
    "print(\"Test loss, Test PSNR:\", results)\n",
    "\n",
    "# Visualize Predictions\n",
    "predictions = model.predict(X_test_gray)\n",
    "\n",
    "def display_results(bw_images, color_images, predictions, n=5):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i in range(n):\n",
    "        # Display original black and white image\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        plt.imshow(bw_images[i].reshape(256, 256), cmap='gray')\n",
    "        plt.title(\"Original B&W\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Display colorized image\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(lab2rgb(np.dstack((bw_images[i].reshape(256, 256, 1), predictions[i] * 128))))\n",
    "        plt.title(\"Colorized\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Display ground truth color image\n",
    "        ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "        plt.imshow(lab2rgb(color_images[i]))\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# Get predictions on test set\n",
    "display_results(X_test_gray, y_test_ab, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
