{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b42298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from Data_processing_functions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a12dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Directory\n",
    "dir_path = 'data'\n",
    "color_dir = os.path.join(dir_path, 'train_color')\n",
    "black_dir = os.path.join(dir_path, 'train_black')\n",
    "\n",
    "# List all images\n",
    "color_images_paths = glob.glob(os.path.join(color_dir, '*.jpg'))\n",
    "black_images_paths = glob.glob(os.path.join(black_dir, '*.jpg'))\n",
    "\n",
    "# Create the original dataset\n",
    "dataset = create_dataset(black_images_paths, color_images_paths, target_size=(256, 256))\n",
    "\n",
    "# Create the dataset with combined grayscale and edge-detected images\n",
    "dataset_with_edges = create_dataset_with_edges(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d5cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking original dataset:\n",
      "Original Batch Size: 32\n",
      "Original Grayscale Images Shape: (32, 256, 256, 1)\n",
      "Original LAB Images Shape: (32, 256, 256, 3)\n",
      "\n",
      "Checking dataset with edges:\n",
      "With Edges Batch Size: 32\n",
      "Combined Images Shape: (32, 256, 256, 2)\n",
      "LAB Images Shape: (32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check the datasets\n",
    "print(\"Checking original dataset:\")\n",
    "for gray_images, lab_images in dataset.take(1):\n",
    "    print(\"Original Batch Size:\", gray_images.shape[0])\n",
    "    print(\"Original Grayscale Images Shape:\", gray_images.shape)\n",
    "    print(\"Original LAB Images Shape:\", lab_images.shape)\n",
    "\n",
    "print(\"\\nChecking dataset with edges:\")\n",
    "for combined_images, lab_images in dataset_with_edges.take(1):\n",
    "    print(\"With Edges Batch Size:\", combined_images.shape[0])\n",
    "    print(\"Combined Images Shape:\", combined_images.shape)\n",
    "    print(\"LAB Images Shape:\", lab_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf4a88",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5933dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "hyperparams = {\n",
    "    'learning_rate': 2e-4,\n",
    "    'beta_1': 0.5,\n",
    "    'batch_size': 1,\n",
    "    'epochs': 50,\n",
    "    'dropout_rate': 0.5,\n",
    "    'lambda_l1': 100,\n",
    "    'batch_norm': True,\n",
    "    'initial_filters': 64,\n",
    "    'kernel_size': 4,\n",
    "    'dropout': True,\n",
    "    'num_layers': 8,\n",
    "    'use_data_augmentation': True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparams['learning_rate'], beta_1=hyperparams['beta_1'])\n",
    "\n",
    "# Define the checkpoint directory\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "# Create model instances\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Create a checkpoint object\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "# Train the model\n",
    "gen_losses, disc_losses, val_gen_losses = model_fit(dataset_with_edges, val_dataset_with_edges, \n",
    "                                                    hyperparams, checkpoint, checkpoint_prefix)\n",
    "\n",
    "generator.save('pix2pix_model_generator.h5')\n",
    "discriminator.save('pix2pix_model_discriminator.h5')\n",
    "\n",
    "\n",
    "# Visualize losses\n",
    "visualize_losses(gen_losses, disc_losses, val_gen_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76be659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379982c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generator model\n",
    "generator = tf.keras.models.load_model('pix2pix_model_generator.h5')\n",
    "\n",
    "# Load the discriminator model\n",
    "discriminator = tf.keras.models.load_model('pix2pix_model_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and preprocess new sample data\n",
    "# def load_and_preprocess_image(image_path, target_size=(256, 256), is_grayscale=True):\n",
    "#     image = Image.open(image_path).convert('L' if is_grayscale else 'RGB')\n",
    "#     image = image.resize(target_size)\n",
    "#     image = np.array(image) / 255.0\n",
    "#     if is_grayscale:\n",
    "#         image = np.expand_dims(image, axis=-1)  # Add channel dimension for grayscale\n",
    "#     return np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "# # Load the generator model\n",
    "# generator = tf.keras.models.load_model('pix2pix_model_generator.h5')\n",
    "\n",
    "# # Load new sample image\n",
    "# new_image_path = 'path/to/your/new/image.jpg'\n",
    "# new_image = load_and_preprocess_image(new_image_path, target_size=(256, 256), is_grayscale=True)\n",
    "\n",
    "# # Predict using the generator\n",
    "# def predict_with_generator(model, input_image):\n",
    "#     prediction = model(input_image, training=False)\n",
    "#     return prediction\n",
    "\n",
    "# # Get prediction\n",
    "# predicted_image = predict_with_generator(generator, new_image)\n",
    "\n",
    "# # Display the result\n",
    "# def display_results(input_image, generated_image, is_grayscale=True):\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.title('Input Image')\n",
    "#     if is_grayscale:\n",
    "#         plt.imshow(input_image[0, :, :, 0], cmap='gray')\n",
    "#     else:\n",
    "#         plt.imshow(input_image[0])\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.title('Generated Image')\n",
    "#     if is_grayscale:\n",
    "#         plt.imshow((generated_image[0, :, :, 0] + 1) / 2, cmap='gray')  # Adjust based on output range\n",
    "#     else:\n",
    "#         plt.imshow((generated_image[0] + 1) / 2)  # Adjust based on output range\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Display results\n",
    "# display_results(new_image, predicted_image, is_grayscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f754c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79a2724",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c07502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252b69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
